import re
import os
import time
import aiohttp
import json
import hashlib
import asyncio
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
from astrbot.api.message_components import Plain, Image, Video, File

# [æ–°å¢] å¼•å…¥åŒç›®å½•ä¸‹çš„ xhs æ¨¡å—
from .xhs import XhsHandler

@register("xhs_parse_hub", "YourName", "èšåˆè§£ææ’ä»¶", "1.4.0")
class ParseHub(Star):
    def __init__(self, context: Context, config: dict):
        super().__init__(context)
        self.config = config
        
        # é€šç”¨é…ç½®
        self.enable_cache = config.get("enable_download_cache", True)
        self.show_all_tips = config.get("show_all_progress_tips", False)
        
        # [æ”¹åŠ¨] åˆå§‹åŒ– XHS å¤„ç†å™¨
        xhs_api = config.get("api_url", "http://127.0.0.1:5556/xhs/")
        self.xhs_handler = XhsHandler(xhs_api)
        
        # ç¼“å­˜ç›®å½•è®¾ç½®
        current_plugin_dir = os.path.dirname(os.path.abspath(__file__))
        self.cache_dir = os.path.join(current_plugin_dir, "xhs_cache") # æ–‡ä»¶å¤¹åå…ˆä¸åŠ¨ï¼Œå…å¾—ä½ å¾—åˆ ç¼“å­˜
        
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
            
        self.cleanup_task = None

    async def initialize(self):
        logger.info(f"========== èšåˆè§£ææ’ä»¶å¯åŠ¨ (v1.4.0 å¤šå¹³å°é‡æ„ç‰ˆ) ==========")
        if self.enable_cache:
            self.cleanup_task = asyncio.create_task(self._auto_cleanup_loop())

    async def terminate(self):
        if self.cleanup_task:
            self.cleanup_task.cancel()

    async def _auto_cleanup_loop(self):
        while True:
            try:
                await asyncio.sleep(3600)
                if os.path.exists(self.cache_dir):
                    now = time.time()
                    for filename in os.listdir(self.cache_dir):
                        file_path = os.path.join(self.cache_dir, filename)
                        if not os.path.isfile(file_path): continue
                        if now - os.path.getmtime(file_path) > 3600:
                            try: os.remove(file_path)
                            except: pass
            except asyncio.CancelledError: break
            except Exception: await asyncio.sleep(60)

    # --- é€šç”¨å·¥å…·æ–¹æ³• ---

    async def try_delete(self, message_obj):
        if not message_obj: return
        if isinstance(message_obj, list):
            for m in message_obj: await self.try_delete(m)
            return
        try:
            if hasattr(message_obj, "delete"):
                if asyncio.iscoroutinefunction(message_obj.delete): await message_obj.delete()
                else: message_obj.delete()
            elif hasattr(message_obj, "recall"):
                if asyncio.iscoroutinefunction(message_obj.recall): await message_obj.recall()
                else: message_obj.recall()
        except Exception as e:
            if self.show_all_tips: logger.warning(f"åˆ é™¤æ¶ˆæ¯å¤±è´¥: {e}")

    def clean_filename(self, title: str) -> str:
        return re.sub(r'[\\/*?:"<>|]', "", title).strip()[:50]

    async def download_file(self, url: str, suffix: str = "") -> str:
        if not url: return None
        try:
            file_hash = hashlib.md5(url.encode('utf-8')).hexdigest()
            filename = f"{file_hash}{suffix}"
            file_path = os.path.join(self.cache_dir, filename)

            if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                os.utime(file_path, None)
                return file_path

            async with aiohttp.ClientSession() as session:
                async with session.get(url) as resp:
                    if resp.status == 200:
                        content = await resp.read()
                        with open(file_path, 'wb') as f:
                            f.write(content)
                        return file_path
                    else:
                        logger.error(f"ä¸‹è½½å¤±è´¥ {resp.status}: {url}")
                        return None
        except Exception as e:
            logger.error(f"ä¸‹è½½å¼‚å¸¸: {e}")
            return None

    # --- æŒ‡ä»¤å¤„ç† ---

    @filter.command("xhs")
    async def xhs_parse(self, event: AstrMessageEvent):
        """å°çº¢ä¹¦è§£æ"""
        message_str = event.message_str
        
        # 1. æå–é“¾æ¥ (è°ƒç”¨ xhs_handler çš„é€»è¾‘)
        target_url = self.xhs_handler.extract_url(message_str)
        
        if not target_url:
            if "http" in message_str: target_url = message_str.strip()
            else:
                yield event.plain_result("âš ï¸ è¯·æä¾›å°çº¢ä¹¦é“¾æ¥ã€‚")
                return

        # 2. å‘é€æç¤º
        parsing_msg = await event.send(event.plain_result("ğŸ” æ­£åœ¨è§£æä¸­..."))
        
        # 3. è°ƒç”¨ XHS æ¨¡å—è¿›è¡Œè§£æ
        # [æ”¹åŠ¨] è¿™é‡Œä¸å†å†™ä¸€å † API è¯·æ±‚ä»£ç ï¼Œè€Œæ˜¯ç›´æ¥è°ƒç”¨ xhs_handler.parse
        result = await self.xhs_handler.parse(target_url)
        
        # åˆ é™¤è§£ææç¤º
        await self.try_delete(parsing_msg)

        if not result["success"]:
            yield event.plain_result(f"âŒ è§£æå¤±è´¥: {result['msg']}")
            return

        # 4. è·å–æ ‡å‡†åŒ–æ•°æ®
        title = result["title"]
        author = result["author"]
        desc = result["desc"]
        work_type = result["type"]
        download_urls = result["download_urls"]
        dynamic_urls = result["dynamic_urls"]
        
        clean_title = self.clean_filename(title)

        # 5. å‘é€æ–‡æ¡ˆ
        info_text = f"ã€æ ‡é¢˜ã€‘{title}\nã€ä½œè€…ã€‘{author}\n\n{desc}"
        if len(info_text) > 250:
            info_text = info_text[:250] + "...\n(æ–‡æ¡ˆè¿‡é•¿å·²æŠ˜å )"

        # è§†é¢‘ç›´é“¾é€»è¾‘
        if work_type == "video" and result["video_url"]:
            info_text += f"\n\nğŸ”— è§†é¢‘ç›´é“¾:\n{result['video_url']}"
            
        yield event.plain_result(info_text)

        # 6. å¤„ç†åª’ä½“å‘é€ (é€šç”¨é€»è¾‘)
        if not download_urls:
            yield event.plain_result("âš ï¸ æœªæ‰¾åˆ°èµ„æºã€‚")
            return

        if self.enable_cache:
            # --- ä¸‹è½½é˜¶æ®µ ---
            msg_text = "ğŸ“¥ æ­£åœ¨ä¸‹è½½è§†é¢‘..." if work_type == "video" else f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ {len(download_urls)} å¼ å›¾ç‰‡..."
            
            download_msg = None
            if self.show_all_tips:
                download_msg = await event.send(event.plain_result(msg_text))
            else:
                logger.info(f"[åå°å¤„ç†] {msg_text}")

            local_paths = []
            if work_type == "video" and result["video_url"]:
                path = await self.download_file(result["video_url"], suffix=".mp4")
                if path: local_paths.append(path)
            else:
                for url in download_urls:
                    path = await self.download_file(url, suffix=".jpg")
                    if path: local_paths.append(path)

            await self.try_delete(download_msg)

            if not local_paths:
                yield event.plain_result("âŒ ä¸‹è½½å¤±è´¥ï¼Œæ— æ³•å‘é€ã€‚")
                return

            # --- ä¸Šä¼ é˜¶æ®µ ---
            upload_text = f"ğŸ“¤ ä¸‹è½½å®Œæˆï¼Œæ­£åœ¨ä¸Šä¼  {len(local_paths)} ä¸ªæ–‡ä»¶..."
            sending_msg = None
            if self.show_all_tips:
                sending_msg = await event.send(event.plain_result(upload_text))
            else:
                logger.info(f"[åå°å¤„ç†] {upload_text}")

            # è§†é¢‘å‘é€
            if work_type == "video":
                local_path = local_paths[0]
                try:
                    final_filename = f"{clean_title}.mp4"
                    payload = event.chain_result([File(name=final_filename, file=local_path)])
                    await event.send(payload)
                except Exception as e:
                    if "Timed out" in str(e):
                        logger.warning("è§†é¢‘ä¸Šä¼ è¶…æ—¶ (å¯èƒ½å·²æˆåŠŸ)")
                    else:
                        logger.error(f"è§†é¢‘å‘é€å¤±è´¥: {e}")
                        yield event.plain_result("âš ï¸ è§†é¢‘ä¸Šä¼ å¤±è´¥ï¼Œè¯·ä½¿ç”¨ç›´é“¾ã€‚")
            
            # å›¾ç‰‡å‘é€
            else: 
                for i, path in enumerate(local_paths):
                    if i > 0: await asyncio.sleep(3) # é—´éš”3ç§’
                    
                    try:
                        final_filename = f"{clean_title}_{i+1}.jpg"
                        chain = [File(name=final_filename, file=path)]
                        
                        # åŠ¨å›¾å¤„ç†é€»è¾‘
                        if dynamic_urls and i < len(dynamic_urls):
                            live_url = dynamic_urls[i]
                            if live_url:
                                chain.append(Plain(f"\nğŸï¸ æ­¤å›¾å« LivePhoto: {live_url}"))
                        
                        payload = event.chain_result(chain)
                        await event.send(payload)

                    except Exception as e:
                        if "Timed out" in str(e):
                            logger.warning(f"ç¬¬ {i+1} å¼ å›¾ç‰‡ä¸Šä¼ è¶…æ—¶ (å¯èƒ½å·²æˆåŠŸ)")
                        else:
                            logger.error(f"æ–‡ä»¶å‘é€å¤±è´¥: {e}")
                            yield event.plain_result(f"âš ï¸ ç¬¬ {i+1} å¼ å‘é€å¤±è´¥ã€‚")

            await self.try_delete(sending_msg)

        else:
            # æ— ç¼“å­˜æ¨¡å¼
            status_msg = None
            if self.show_all_tips:
                status_msg = await event.send(event.plain_result("ğŸš€ æ­£åœ¨é€šè¿‡ç½‘ç»œç›´å‘..."))
                
            if work_type == "video":
                try:
                    yield event.chain_result([Video.fromURL(result["video_url"])])
                except: yield event.plain_result("âš ï¸ å‘é€å¤±è´¥ã€‚")
            else:
                for url in download_urls:
                    try:
                        yield event.chain_result([Image.fromURL(url)])
                    except: pass
            await self.try_delete(status_msg)