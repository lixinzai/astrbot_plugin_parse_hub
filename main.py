import re
import os
import time
import aiohttp
import json
import hashlib
import asyncio
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
# [ä¿®æ­£] ç§»é™¤ MessageChain çš„å¯¼å…¥ï¼Œä¿ç•™åŸºç¡€ç»„ä»¶
from astrbot.api.message_components import Plain, Image, Video, File

@register("xhs_parse_hub", "YourName", "å°çº¢ä¹¦åŽ»æ°´å°è§£æžæ’ä»¶", "1.0.0")
class XhsParseHub(Star):
    def __init__(self, context: Context, config: dict):
        super().__init__(context)
        self.config = config
        self.api_url = config.get("api_url", "http://127.0.0.1:5556/xhs/")
        self.enable_cache = config.get("enable_download_cache", True)
        
        current_plugin_dir = os.path.dirname(os.path.abspath(__file__))
        self.cache_dir = os.path.join(current_plugin_dir, "xhs_cache")
        
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
            
        self.cleanup_task = None

    async def initialize(self):
        logger.info(f"========== å°çº¢ä¹¦æ’ä»¶å¯åŠ¨ (v1.0.0 Fixed) ==========")
        if self.enable_cache:
            self.cleanup_task = asyncio.create_task(self._auto_cleanup_loop())

    async def terminate(self):
        if self.cleanup_task:
            self.cleanup_task.cancel()

    async def _auto_cleanup_loop(self):
        while True:
            try:
                await asyncio.sleep(3600)
                if os.path.exists(self.cache_dir):
                    now = time.time()
                    for filename in os.listdir(self.cache_dir):
                        file_path = os.path.join(self.cache_dir, filename)
                        if not os.path.isfile(file_path): continue
                        if now - os.path.getmtime(file_path) > 3600:
                            try: os.remove(file_path)
                            except: pass
            except asyncio.CancelledError: break
            except Exception: await asyncio.sleep(60)

    # å°è¯•æ’¤å›ž/åˆ é™¤æ¶ˆæ¯
    async def try_delete(self, message_obj):
        if not message_obj: return
        try:
            # ä¸åŒçš„é€‚é…å™¨å¯èƒ½æ–¹æ³•åä¸åŒï¼Œåšå…¼å®¹å¤„ç†
            if hasattr(message_obj, "delete"):
                await message_obj.delete()
            elif hasattr(message_obj, "recall"):
                await message_obj.recall()
        except: pass

    def extract_url(self, text: str):
        pattern = r'(https?://[^\s]+)'
        match = re.search(pattern, text)
        if match: return match.group(0)
        return None

    def clean_filename(self, title: str) -> str:
        return re.sub(r'[\\/*?:"<>|]', "", title).strip()[:50]

    async def download_file(self, url: str, suffix: str = "") -> str:
        if not url: return None
        try:
            file_hash = hashlib.md5(url.encode('utf-8')).hexdigest()
            filename = f"{file_hash}{suffix}"
            file_path = os.path.join(self.cache_dir, filename)

            if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                os.utime(file_path, None)
                return file_path

            async with aiohttp.ClientSession() as session:
                async with session.get(url) as resp:
                    if resp.status == 200:
                        content = await resp.read()
                        with open(file_path, 'wb') as f:
                            f.write(content)
                        return file_path
                    else:
                        logger.error(f"ä¸‹è½½å¤±è´¥ {resp.status}: {url}")
                        return None
        except Exception as e:
            logger.error(f"ä¸‹è½½å¼‚å¸¸: {e}")
            return None

    @filter.command("xhs")
    async def xhs_parse(self, event: AstrMessageEvent):
        message_str = event.message_str
        target_url = self.extract_url(message_str)
        
        if not target_url:
            if "http" in message_str: target_url = message_str.strip()
            else:
                yield event.plain_result("âš ï¸ è¯·æä¾›é“¾æŽ¥ã€‚")
                return

        # [ä¿®æ­£] ç›´æŽ¥ä½¿ç”¨ event.plain_result æž„å»ºå‘é€å¯¹è±¡
        parsing_msg = await event.send(event.plain_result("ðŸ” æ­£åœ¨è§£æžä¸­..."))
        
        res_json = None
        try:
            async with aiohttp.ClientSession() as session:
                timeout = aiohttp.ClientTimeout(total=15)
                async with session.post(self.api_url, json={"url": target_url}, timeout=timeout) as resp:
                    await self.try_delete(parsing_msg) # åˆ é™¤æç¤º
                    
                    if resp.status != 200:
                        yield event.plain_result(f"âŒ è§£æžè¯·æ±‚å¤±è´¥: {resp.status}")
                        return
                    res_json = await resp.json()
        except Exception as e:
            await self.try_delete(parsing_msg)
            yield event.plain_result(f"âŒ è¿žæŽ¥é”™è¯¯: {e}")
            return

        # æå–æ•°æ®
        data = res_json.get("data")
        if not data:
            msg = res_json.get("message", "æœªçŸ¥é”™è¯¯")
            yield event.plain_result(f"âŒ è§£æžå¤±è´¥: {msg}")
            return

        title = data.get("ä½œå“æ ‡é¢˜", "æ— æ ‡é¢˜")
        author = data.get("ä½œè€…æ˜µç§°", "æœªçŸ¥ä½œè€…")
        desc = data.get("ä½œå“æè¿°", "")
        work_type = data.get("ä½œå“ç±»åž‹", "")
        download_urls = data.get("ä¸‹è½½åœ°å€", [])
        dynamic_urls = data.get("åŠ¨å›¾åœ°å€", [])
        
        clean_title = self.clean_filename(title)

        # æž„å»ºæ–‡æ¡ˆ
        info_text = f"ã€æ ‡é¢˜ã€‘{title}\nã€ä½œè€…ã€‘{author}\n\n{desc}"
        if len(info_text) > 250:
            info_text = info_text[:250] + "...\n(æ–‡æ¡ˆè¿‡é•¿å·²æŠ˜å )"

        video_direct_link = None
        if work_type == "è§†é¢‘" and download_urls:
            video_direct_link = download_urls[0]
            info_text += f"\n\nðŸ”— è§†é¢‘ç›´é“¾:\n{video_direct_link}"
            
        yield event.plain_result(info_text)

        # å¤„ç†åª’ä½“
        if not download_urls:
            yield event.plain_result("âš ï¸ æœªæ‰¾åˆ°èµ„æºã€‚")
            return

        if self.enable_cache:
            # --- ä¸‹è½½é˜¶æ®µ ---
            msg_text = "ðŸ“¥ æ­£åœ¨ä¸‹è½½è§†é¢‘..." if work_type == "è§†é¢‘" else f"ðŸ“¥ æ­£åœ¨ä¸‹è½½ {len(download_urls)} å¼ å›¾ç‰‡..."
            # [ä¿®æ­£] ä½¿ç”¨ event.plain_result
            download_msg = await event.send(event.plain_result(msg_text))

            local_paths = []
            if work_type == "è§†é¢‘" and video_direct_link:
                path = await self.download_file(video_direct_link, suffix=".mp4")
                if path: local_paths.append(path)
            else:
                for url in download_urls:
                    path = await self.download_file(url, suffix=".jpg")
                    if path: local_paths.append(path)

            await self.try_delete(download_msg)

            if not local_paths:
                yield event.plain_result("âŒ ä¸‹è½½å¤±è´¥ï¼Œæ— æ³•å‘é€ã€‚")
                return

            # --- ä¸Šä¼ é˜¶æ®µ ---
            # [ä¿®æ­£] ä½¿ç”¨ event.plain_result
            sending_msg = await event.send(event.plain_result(f"ðŸ“¤ ä¸‹è½½å®Œæˆï¼Œæ­£åœ¨ä¸Šä¼  {len(local_paths)} ä¸ªæ–‡ä»¶..."))

            # è§†é¢‘ (å¼ºåˆ¶æ–‡ä»¶)
            if work_type == "è§†é¢‘":
                local_path = local_paths[0]
                try:
                    final_filename = f"{clean_title}.mp4"
                    yield event.chain_result([File(name=final_filename, file=local_path)])
                except Exception as e:
                    logger.error(f"è§†é¢‘å‘é€å¤±è´¥: {e}")
                    yield event.plain_result("âš ï¸ è§†é¢‘ä¸Šä¼ å¤±è´¥ï¼Œè¯·ä½¿ç”¨ç›´é“¾ã€‚")
            
            # å›¾æ–‡ (å¼ºåˆ¶æ–‡ä»¶)
            else: 
                for i, path in enumerate(local_paths):
                    if i > 0: await asyncio.sleep(2)
                    
                    try:
                        final_filename = f"{clean_title}_{i+1}.jpg"
                        chain = [File(name=final_filename, file=path)]
                        
                        if dynamic_urls and i < len(dynamic_urls):
                            live_url = dynamic_urls[i]
                            if live_url:
                                chain.append(Plain(f"\nðŸŽžï¸ æ­¤å›¾å« LivePhoto: {live_url}"))
                        
                        yield event.chain_result(chain)
                    except Exception as e:
                        logger.error(f"æ–‡ä»¶å‘é€å¤±è´¥: {e}")
                        yield event.plain_result(f"âš ï¸ ç¬¬ {i+1} å¼ å‘é€å¤±è´¥ã€‚")

            await self.try_delete(sending_msg)

        else:
            # æ— ç¼“å­˜æ¨¡å¼
            status_msg = await event.send(event.plain_result("ðŸš€ æ­£åœ¨é€šè¿‡ç½‘ç»œç›´å‘..."))
            if work_type == "è§†é¢‘":
                try:
                    yield event.chain_result([Video.fromURL(video_direct_link)])
                except: yield event.plain_result("âš ï¸ å‘é€å¤±è´¥ã€‚")
            else:
                for url in download_urls:
                    try:
                        yield event.chain_result([Image.fromURL(url)])
                    except: pass
            await self.try_delete(status_msg)